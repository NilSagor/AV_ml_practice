{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#install the pydrive wrapper and import libraries\n",
    "!pip install -U -q PyDrive\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials\n",
    "\n",
    "# Authenticate and create the pydrive client\n",
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# running this cell to mount google drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls '/content/drive/My Drive/AV_data/WNS_Analytics_Wizerd_23424/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !unzip -q '/content/drive/My Drive/AV_data/WNS_Analytics_Wizard_24082019/sample_submission_IPsBlCT.zip'\n",
    "# !unzip -q '/content/drive/My Drive/AV_data/WNS_Analytics_Wizard_24082019/test.zip'\n",
    "# !unzip -q '/content/drive/My Drive/AV_data/WNS_Analytics_Wizard_24082019/train.zip'\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load packages\n",
    "import numpy as np,\n",
    "import pandas as pd,\n",
    "from scipy.stats import mode,\n",
    "from sklearn import metrics, preprocessing, model_selection,\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold,\n",
    "from sklearn.model_selection import GroupKFold, GridSearchCV,\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,roc_auc_score,\n",
    "from collections import defaultdict, Counter,\n",
    "import lightgbm as lgb,\n",
    "import matplotlib.pyplot as plt,\n",
    "import seaborn as sns\n",
    "\n",
    "import string,\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "\n",
    "pd.options.display.max_columns = 100\n",
    "from plotly import tools\n",
    "import plotly.graph_objs as go,\n",
    "from plotly.offline import init_notebook_mode, iplot,\n",
    "import warnings,\n",
    "warnings.filterwarnings(\\\"ignore\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.groupby('is_click')['impression_id'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['is_click'].value_counts(normalize=True)\n",
    "#We have imbalance target class. We need to use some upsampling techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Number of samples in train: {train_df.shape[0]}'),\n",
    "print(f'Number of columns in train: {train_df.shape[1]}'),\n",
    "for col in train_df.columns:\n",
    "    if train_df[col].isnull().any():\n",
    "        print(col, train_df[col].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_data = (((train_df.isnull().sum())*100)/len(train_df))\n",
    "missing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Read item_data\n",
    "item_data_df = pd.read_csv('item_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_data_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_data_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### View Log data\n",
    "view_log_df = pd.read_csv('view_log.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_log_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_log_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_log_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the datasets View Log and Item Data\n",
    "#Join the train data and quality and process based on the key timestamp\n",
    "item_view_log_df = pd.merge(view_log_df, item_data_df, on='item_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_view_log_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_view_log_df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_view_log_df.shape\n",
    "item_view_log_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_view_log_df[item_view_log_df['user_id'] ==0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_view_log_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['device_type']\n",
    "for col in cols:\n",
    "    if item_view_log_df[col].dtype==object:\n",
    "        print(col)\n",
    "        lbl = preprocessing.LabelEncoder()\n",
    "        lbl.fit(list(item_view_log_df[col].values.astype('str')))\n",
    "        item_view_log_df[col] = lbl.transform(list(item_view_log_df[col].values.astype('str')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_view_log_df['server_time'] = pd.to_datetime(item_view_log_df['server_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_view_log_df[\\\"log_Year\\\"] = item_view_log_df[\\\"server_time\\\"].dt.year\n",
    "item_view_log_df[\\\"log_Month\\\"] = item_view_log_df[\\\"server_time\\\"].dt.month\n",
    "item_view_log_df[\\\"log_Day\\\"] = item_view_log_df[\\\"server_time\\\"].dt.day\n",
    "item_view_log_df[\\\"log_WeekDay\\\"] = item_view_log_df[\\\"server_time\\\"].dt.weekday\n",
    "item_view_log_df[\\\"log_time\\\"] = item_view_log_df[\\\"server_time\\\"].dt.time\n",
    "item_view_log_df[['log_h','log_m','log_s']] = item_view_log_df['log_time'].astype(str).str.split(':', expand=True).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_view_log_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_view_log_df['log_Year'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_view_log_df['log_Month'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_view_log_df['log_Day'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Convert all the variables into category\\n\",\n",
    "        \"# item_view_log_df.session_id=dftest.session_id.astype(np.object)\\n\",\n",
    "        \"# item_view_log_df.user_id=dftest.user_id.astype(np.object)\\n\",\n",
    "        \"# item_view_log_df.item_id=dftest.item_id.astype(np.object)\\n\",\n",
    "        \"\\n\",\n",
    "        \"# item_view_log_df.category_1=dftest.category_1.astype(np.object)\\n\",\n",
    "        \"# item_view_log_df.category_2=dftest.category_2.astype(np.object)\\n\",\n",
    "        \"# item_view_log_df.category_3=dftest.category_3.astype(np.object)\\n\",\n",
    "        \"\\n\",\n",
    "        \"# item_view_log_df.product_type=dftest.product_type.astype(np.object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Grouping the viewed log data using and extracting features\n",
    "item_view_log_df['device_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_view_log_df['product_type'].value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "days_active = item_view_log_df.reset_index().groupby(\n",
    "    ['user_id'])['server_time'].agg(\n",
    "    lambda x: (x.max() - x.min()).days if (x.max() - x.min()).days !=0 else 1)\n",
    "unique_days_active = item_view_log_df.reset_index().groupby(\n",
    "    ['user_id'])['server_time'].agg(\n",
    "    lambda x: len(np.unique(x.dt.dayofyear)))\n",
    "user_time_features = days_active.reset_index().merge(\n",
    "    unique_days_active.reset_index(),on='user_id',how = 'left')\n",
    "user_time_features.columns = ['user_id','log_days_active','log_unique_days_active']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_time_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_time_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_time_features['user_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_view_log_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_view_log_df[item_view_log_df['session_id'] == 112333]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_view_log_df['session_id'].value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_view_log_df['category_1'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_view_log_df['category_2'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_view_log_df['category_3'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_view_log_df['item_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_view_log_df['product_type'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_view_log_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_view_log_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_Month_df = pd.pivot_table(item_view_log_df, \n",
    "                              values=\\\"session_id\\\", \n",
    "                              index=\\\"user_id\\\", \n",
    "                              columns=\\\"log_Month\\\", \n",
    "                              aggfunc=\\\"count\\\", \n",
    "                              fill_value=0).reset_index()\n",
    "print(log_Month_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_Month_df.columns = [\\\"user_id\\\"] + [\\\"log_Month_\\\"+str(i) for i in range(10,13)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_WeekDay_df = pd.pivot_table(item_view_log_df, \n",
    "                                values=\\\"session_id\\\", \n",
    "                                index=\\\"user_id\\\", \n",
    "                                columns=\\\"log_WeekDay\\\", \n",
    "                                aggfunc=\\\"count\\\", \n",
    "                                fill_value=0).reset_index()\n",
    "print(log_WeekDay_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_WeekDay_df.columns = [\\\"user_id\\\"] + [\\\"log_WeekDay_\\\"+str(i) for i in range(0,7)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_WeekDay_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_WeekDay_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_view_log_df[(item_view_log_df['user_id'] == 4557)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_view_log_df[(item_view_log_df['user_id'] == 4557) & (item_view_log_df['category_1'] == 16.0)].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_view_log_df['category_1'].min(), item_view_log_df['category_1'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_1_df = pd.pivot_table(item_view_log_df, \n",
    "                               values=\\\"item_id\\\", \n",
    "                               index=\\\"user_id\\\", \n",
    "                               columns=\\\"category_1\\\", \n",
    "                               aggfunc=\\\"count\\\", \n",
    "                               fill_value=0).reset_index()\n",
    "print(category_1_df.columns)\n",
    "category_1_df.columns = [\\\"user_id\\\"] + [\\\"cat_1_\\\"+str(i) for i in range(0,17)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_1_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_1_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_view_log_df['category_2'].min(), item_view_log_df['category_2'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_2_df = pd.pivot_table(item_view_log_df, \n",
    "                               values=\\\"item_id\\\", \n",
    "                               index=\\\"user_id\\\", \n",
    "                               columns=\\\"category_2\\\", \n",
    "                               aggfunc=\\\"count\\\", \n",
    "                               fill_value=0).reset_index()\n",
    "category_2_df.columns = [\\\"user_id\\\"] + [\\\"cat_2_\\\"+str(i) for i in range(0,79)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_2_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_view_log_df['category_3'].min(), item_view_log_df['category_3'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_view_log_df['product_type'].min(), item_view_log_df['product_type'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [0,7,15,22,31]\n",
    "group_names = [1, 2, 3, 4]\n",
    "item_view_log_df['Month_wk_grp'] = pd.cut(item_view_log_df['log_Day'], bins, labels=group_names)\n",
    "item_view_log_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_view_log_df['Month_wk_grp'] = pd.to_numeric(item_view_log_df['Month_wk_grp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_Month_wk_grp_df = pd.pivot_table(item_view_log_df, \n",
    "                                     index=\\\"user_id\\\", \n",
    "                                     columns=\\\"Month_wk_grp\\\", \n",
    "                                     values=\\\"session_id\\\", \n",
    "                                     aggfunc=\\\"count\\\", \n",
    "                                     fill_value=0).reset_index()\\n\",\n",
    "log_Month_wk_grp_df.columns = [\\\"user_id\\\"] + [\\\"log_Month_wk_grp_\\\"+str(i) for i in range(1,5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_Month_wk_grp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['app_code'].value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib_venn import venn2, venn2_circles\n",
    "\n",
    "def get_venn(axarr, feature):\n",
    "    axarr[0,0].set_title(f'Overlap between {feature} in train and test')\n",
    "    venn2([set(train_df[feature].values), set(test_df[feature].values)], set_labels = ('train','test'), ax=axarr[0,0])\n",
    "    axarr[0,1].set_title(f'Overlap between {feature} in train and hist')\n",
    "    venn2([set(train_df[feature].values), \n",
    "           set(item_view_log_df[feature].values)], \n",
    "          set_labels = ('train','hist'), ax=axarr[0,1])\n",
    "    axarr[1,0].set_title(f'Overlap between {feature} in test and hist')\n",
    "    venn2([set(test_df[feature].values), \n",
    "           set(item_view_log_df[feature].values)], \n",
    "          set_labels = ('test','hist'), ax=axarr[1,0])\n",
    "    axarr[1,1].set_title(f'Overlap between {feature} in train and test')\n",
    "    venn2([set(train_df[feature].values), \n",
    "           set(test_df[feature].values)], \n",
    "           set_labels = ('train','test'), ax=axarr[1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axarr = plt.subplots(2,2, figsize=(10,6))\n",
    "get_venn(axarr, 'user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Join Train and LogView data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_view_log_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[train_df['user_id'] == 87862]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['os_version'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# * join the datasets\\n\",\n",
    "train_df['is_train']  = 1\n",
    "test_df['is_click'] = -99\n",
    "test_df['is_train'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = train_df.append(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df['impression_time'] = pd.to_datetime(full_df['impression_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df[\\\"Year\\\"] = full_df[\\\"impression_time\\\"].dt.year\n",
    "full_df[\\\"Month\\\"] = full_df[\\\"impression_time\\\"].dt.month\n",
    "full_df[\\\"Day\\\"] = full_df[\\\"impression_time\\\"].dt.day\n",
    "full_df[\\\"WeekDay\\\"] = full_df[\\\"impression_time\\\"].dt.weekday\n",
    "full_df[\\\"time\\\"] = full_df[\\\"impression_time\\\"].dt.time\n",
    "full_df[['h','m','s']] = full_df['time'].astype(str).str.split(':', expand=True).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = pd.pivot_table(full_df, index=\\\"user_id\\\", \n",
    "                     columns=\\\"Year\\\", \n",
    "                     values=\\\"impression_id\\\", \n",
    "                     aggfunc=\\\"count\\\", \n",
    "                     fill_value=0).reset_index()\\n\",\n",
    "full_df = pd.merge(full_df, gdf, on=\\\"user_id\\\", how=\\\"left\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df['Year'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = pd.pivot_table(full_df, \n",
    "                     index=\\\"user_id\\\", \n",
    "                     columns=\\\"Month\\\", \n",
    "                     values=\\\"impression_id\\\", \n",
    "                     aggfunc=\\\"count\\\", \n",
    "                     fill_value=0).reset_index()\n",
    "gdf.columns = [\\\"user_id\\\"] + [\\\"Month_\\\"+str(i) for i in range(11,13)]\n",
    "full_df = pd.merge(full_df, gdf, on=\\\"user_id\\\", how=\\\"left\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df['app_code'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = pd.pivot_table(full_df, \n",
    "                     index=\\\"user_id\\\", \n",
    "                     columns=\\\"Day\\\", \n",
    "                     values=\\\"impression_id\\\", \n",
    "                     aggfunc=\\\"count\\\", \n",
    "                     fill_value=0).reset_index()\n",
    "gdf.columns = [\\\"user_id\\\"] + [\\\"Day_\\\"+str(i) for i in range(1,31)]\n",
    "full_df = pd.merge(full_df, gdf, on=\\\"user_id\\\", how=\\\"left\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### pivot on MOdel and Year\\n\",\n",
    "gdf = pd.pivot_table(full_df, index=\\\"user_id\\\", \n",
    "                     columns=\\\"WeekDay\\\", \n",
    "                     values=\\\"impression_id\\\", \n",
    "                     aggfunc=\\\"count\\\", \n",
    "                     fill_value=0).reset_index()\n",
    "gdf.columns = [\\\"user_id\\\"] + [\\\"WeekDay_\\\"+str(i) for i in range(0,7)]\n",
    "full_df = pd.merge(full_df, gdf, on=\\\"user_id\\\", how=\\\"left\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad_days_active = full_df.reset_index().groupby(['user_id'])['impression_time'].agg(\n",
    "    lambda x: (x.max() - x.min()).days if (x.max() - x.min()).days !=0 else 1)\n",
    "ad_unique_days_active = full_df.reset_index().groupby(['user_id'])['impression_time'].agg(\n",
    "    lambda x: len(np.unique(x.dt.dayofyear)))\n",
    "ad_user_time_features = ad_days_active.reset_index().merge(\n",
    "    ad_unique_days_active.reset_index(),\n",
    "    on='user_id',how = 'left')\n",
    "ad_user_time_features.columns = ['user_id','ad_days_active','ad_unique_days_active']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = pd.merge(full_df, ad_user_time_features, on=\\\"user_id\\\", how=\\\"left\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = pd.merge(full_df, user_time_features, on=\\\"user_id\\\", how=\\\"left\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = pd.merge(full_df, category_1_df, on=\\\"user_id\\\", how=\\\"left\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = pd.merge(full_df, log_WeekDay_df, on=\\\"user_id\\\", how=\\\"left\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = pd.merge(full_df, log_Month_df, on=\\\"user_id\\\", how=\\\"left\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = pd.merge(full_df, category_2_df, on=\\\"user_id\\\", how=\\\"left\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = pd.merge(full_df, log_Day_df, on=\\\"user_id\\\", how=\\\"left\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = pd.merge(full_df, log_Month_wk_grp_df, on=\\\"user_id\\\", how=\\\"left\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Add the user time features from the item log window\"\n",
    "testcount = len(test_df)\n",
    "count = len(full_df)-testcount\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df['app_code'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df['os_version'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Convertign into one-hot encoding\"\n",
    "cols = ['os_version']\\n\",\n",
    "for col in cols:\n",
    "    if full_df[col].dtype==object:\n",
    "        print(col)\n",
    "        lbl = preprocessing.LabelEncoder()\n",
    "        lbl.fit(list(full_df[col].values.astype('str')))\n",
    "        full_df[col] = lbl.transform(list(full_df[col].values.astype('str')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ATTRIBUTION_CATEGORIES = [ \n",
    "         # V1 Features #\\n\",\n",
    "           ###############\\n\",\n",
    "         ['app_code'], ['os_version'], ['is_4G'],\n",
    "        \n",
    "      # V2 Features #\\n\",\n",
    "        ###############\\n\",\n",
    "          ['app_code', 'os_version'],\n",
    "          ['app_code', 'is_4G'],\n",
    "           ['os_version', 'is_4G']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ATTRIBUTION_CATEGORIES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find frequency of is_attributed for each unique value in column\n",
    "freqs = {}\n",
    "for cols in ATTRIBUTION_CATEGORIES:\n",
    "    # New feature name\\n\",\n",
    "     new_feature = '_'.join(cols)+'_confRate'    ,\n",
    "        \n",
    "      # Perform the groupby\n",
    "      group_object = full_df.groupby(cols)\n",
    "      \n",
    "       # Group sizes    \\n\",\n",
    "       group_sizes = group_object.size()\\n\",\n",
    "       log_group = np.log(100000) # 1000 views -> 60% confidence, 100 views -> 40% confidence \\n\",\n",
    "    print(\\\">> Calculating confidence-weighted rate for: {}.\\\\n   \n",
    "          Saving to: {}. Group Max /Mean / Median / Min: {} / {} / {} / {}\\\".format(\n",
    "            cols, new_feature,\n",
    "         group_sizes.max(), \n",
    "           np.round(group_sizes.mean(), 2),\\n\",\n",
    "             np.round(group_sizes.median(), 2),\\n\",\n",
    "               group_sizes.min()\\n\",\n",
    "         ))  \n",
    "           \n",
    "         # Aggregation function\\n\",\n",
    "         def rate_calculation(x):\\n\",\n",
    "         \"\"\"Calculate the attributed rate. Scale by confidence\"\"\"\n",
    "        rate = x.sum() / float(x.count())\n",
    "             conf = np.min([1, np.log(x.count()) / log_group])\n",
    "             return rate * conf\n",
    "        \n",
    "          # Perform the merge\\n\",\n",
    "          full_df = full_df.merge(\\n\",\n",
    "             group_object['is_click']. \\\\\n",
    "                   apply(rate_calculation). \\\\\n",
    "                 reset_index(). \n",
    "                   rename( \n",
    "                      index=str,\n",
    "                     columns={'is_click': new_feature}\n",
    "                    )[cols + [new_feature]],\n",
    "              on=cols, how='left'\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = item_view_log_df.groupby('user_id').size().reset_index()\n",
    "temp.columns = ['user_id', 'count']\n",
    "full_df = full_df.join(temp.set_index('user_id'), on = 'user_id', how = 'left')\n",
    "full_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmep = item_view_log_df.groupby(['user_id', 'server_time']).size().reset_index()\n",
    "tmep.columns = ['user_id', 'server_time', 'same_user_time_count']\n",
    "\n",
    "temp = tmep.groupby('user_id').agg({\\\"same_user_time_count\\\": ['var', 'mean']}).reset_index()\n",
    "temp.columns = ['user_id', 'same_user_time_count_var', 'same_user_time_count_mean']\n",
    "temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = full_df.join(temp.set_index('user_id'), on = 'user_id', how = 'left')\n",
    "full_df['same_user_time_count_var'] = full_df['same_user_time_count_var'].fillna(0)\n",
    "full_df['same_user_time_count_mean'] = full_df['same_user_time_count_mean'].fillna(0)\n",
    "full_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prev_view(user_id, DateTime):\n",
    "    user_id_dict = defaultdict()\n",
    "    prev_view = np.zeros(len(user_id))\n",
    "    for i, (u, t) in enumerate(zip(user_id, DateTime)):\n",
    "        if u in user_id_dict:\n",
    "            prev_view[i] = (t - user_id_dict[u])\n",
    "            user_id_dict[u] = t\\n\",\n",
    "        else:\n",
    "            prev_view[i] = 0\n",
    "            user_id_dict[u] = t\n",
    "    prev_view = prev_view/10**10\n",
    "    return prev_view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expanding_count(x):\\n\",\n",
    "        \"    exp_count = []\\n\",\n",
    "        \"    count_dict = defaultdict(np.int32)\\n\",\n",
    "        \"    for i in x:\\n\",\n",
    "        \"        if i in count_dict:\\n\",\n",
    "        \"            count_dict[i] += 1\\n\",\n",
    "        \"            exp_count.append(count_dict[i])\\n\",\n",
    "        \"        else:\\n\",\n",
    "        \"            exp_count.append(1)\\n\",\n",
    "        \"            count_dict[i] = 1\\n\",\n",
    "        \"    return exp_count, count_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_likelihood(df, cat_var, target, alpha = 0.5):\\n\",\n",
    "        \"    P_c = df.groupby(cat_var)[target].transform('mean')\\n\",\n",
    "        \"    P_global = df[target].mean()\\n\",\n",
    "        \"    n_c = df.groupby(cat_var)[target].transform('count')\\n\",\n",
    "        \"    enc = (P_c*n_c + P_global*alpha)/(n_c + alpha)\\n\",\n",
    "        \"    temp = df[[cat_var]]\\n\",\n",
    "        \"    temp['enc'] = enc\\n\",\n",
    "        \"    return temp.groupby(cat_var).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_view_log_df['user_id_count'] = item_view_log_df['user_id'].map(Counter(item_view_log_df['user_id']))\n",
    "exp_count, _ = expanding_count(item_view_log_df['user_id'])\n",
    "item_view_log_df['user_id_exp_count'] = exp_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_view_log_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_view_log_df['user_id'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_view_log_df[item_view_log_df['user_id'] == 74788].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_view_log_df['user_id_exp_count'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_view_log_df['user_itemid'] = item_view_log_df['user_id'].astype(str)+'_'+item_view_log_df['item_id'].astype(str)\n",
    "item_view_log_df['user_itemid_count'] = item_view_log_df['user_itemid'].map(Counter(item_view_log_df['user_itemid']))\n",
    "exp_count, _ = expanding_count(item_view_log_df['user_itemid'])\n",
    "item_view_log_df['user_itemid_count'] = exp_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_view_log_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_view_log_df['user_itemid_count'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_view_log_df[item_view_log_df['user_itemid_count'] == 217]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_view_log_df['user_product'] = item_view_log_df['user_id'].astype(str)+'_'+item_view_log_df['product_type'].astype(str)\n",
    "item_view_log_df['user_product_count'] = item_view_log_df['user_product'].map(Counter(item_view_log_df['user_product']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_view_log_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_view_log_df['product_item_id'] = item_view_log_df['product_type'].astype(str) + '_' + item_view_log_df['item_id'].astype(str)\n",
    "item_view_log_df['product_item_id_count'] = item_view_log_df['product_item_id'].map(Counter(item_view_log_df['product_item_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_view_log_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_view_log_df['user_product_item_id'] = item_view_log_df['user_id'].astype(str)+ '_' + item_view_log_df['product_item_id']\n",
    "item_view_log_df['user_itemid_product_count'] = item_view_log_df['user_product_item_id'].map(Counter(item_view_log_df['user_product_item_id']))\n",
    "exp_count, _ = expanding_count(item_view_log_df['user_product_item_id'])\n",
    "item_view_log_df['user_itemid_product_exp_count'] = exp_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_view_log_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = item_view_log_df.groupby(['user_id', 'user_itemid_product_count']).size().unstack().fillna(0)\n",
    "full_df = full_df.join(temp, on = 'user_id', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df[full_df[217] == 217]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df[full_df[217] == 217]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = full_df[:count]\n",
    "test = full_df[count:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(full_df.shape)\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train.copy()\n",
    "test_df = test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['is_click'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_vars = ['app_code', 'os_version', 'is_4G']\n",
    "# getting mean encoding features\n",
    "cvlist = list(KFold(n_splits = 10, random_state = 1).split(train_df))\\n\",\n",
    "for var in cat_vars + ['user_id']:\n",
    "    mean_enc_var = np.zeros(len(train_df))\n",
    "    for tr_idx, val_idx in cvlist:\n",
    "        X_tr, X_val = train_df.loc[tr_idx], train_df.loc[val_idx]\n",
    "        X_tr_mean = mean_likelihood(X_tr, var, 'is_click')\\n\",\n",
    "        mean_enc_var[val_idx] = X_val[var].map(X_tr_mean['enc'])\n",
    "        train_df[f'mean_enc_{var}'] = mean_enc_var\n",
    "        train_df[f'mean_enc_{var}'] = train_df[f'mean_enc_{var}'].fillna(train_df[f'mean_enc_{var}'].mean())\n",
    "        test_df[f'mean_enc_{var}'] = test_df[var].map(mean_likelihood(train_df, var, 'is_click')['enc'])\n",
    "        test_df[f'mean_enc_{var}'] = test_df[f'mean_enc_{var}'].fillna(train_df[f'mean_enc_{var}'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train_df.drop(['impression_id', 'impression_time','user_id', 'is_click', 'is_train', 'time'],axis=1)\n",
    "test_X = test_df.drop(['impression_id', 'impression_time','user_id', 'is_click', 'is_train', 'time'],axis=1)\n",
    "y = train_df['is_click'].values\n",
    "train_y = y\n",
    "        \n",
    "X = train_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardization\\n\",\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc=StandardScaler()\n",
    "train_X=sc.fit_transform(train_X)\n",
    "X = train_X\n",
    "test_X=sc.transform(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runLGB(train_X, train_y, test_X, test_y=None, test_X2=None):\n",
    "    params = {}\n",
    "    params[\\\"objective\\\"] = \\\"binary\\”\n",
    "    params['metric'] = 'auc'\n",
    "    params[\\\"max_depth\\\"] = 8    \n",
    "     params[\\\"min_data_in_leaf\\\"] = 1\n",
    "    params[\\\"learning_rate\\\"] = 0.01\n",
    "      params[\\\"bagging_fraction\\\"] = 0.7\n",
    "       params[\\\"feature_fraction\\\"] = 0.7\n",
    "     params[\\\"bagging_freq\\\"] = 1\n",
    "       params[\\\"bagging_seed\\\"] = 0\n",
    "     params[\\\"verbosity\\\"] = -1\n",
    "         num_rounds = 20000\n",
    "       \n",
    "        plst = list(params.items())\n",
    "           lgtrain = lgb.Dataset(train_X, label=train_y)\n",
    "        \n",
    "    if test_y is not None:        \n",
    "        lgtest = lgb.Dataset(test_X, label=test_y)       \n",
    "        model = lgb.train(params, lgtrain,  num_rounds,\n",
    "                               valid_sets=[lgtrain,lgtest],                          \n",
    "        \n",
    "                             early_stopping_rounds=100, verbose_eval=500)\n",
    "            \n",
    "    else:\n",
    "        lgtest = lgb.Dataset(test_X)\n",
    "        model = lgb.train(params, lgtrain,   num_rounds)\n",
    "        \n",
    "    pred_test_y = model.predict(test_X, num_iteration=model.best_iteration)\n",
    "    pred_test_y = (pred_test_y)\n",
    "        \n",
    "    pred_test_y2 = model.predict(test_X2, num_iteration=model.best_iteration)\n",
    "    pred_test_y2 = (pred_test_y2)\n",
    "       \n",
    "         loss = 0\n",
    "         if test_y is not None:           \n",
    "              loss = roc_auc_score((test_y), pred_test_y)    \n",
    "            return pred_test_y, loss, pred_test_y2, model\n",
    "         else:\n",
    "             return pred_test_y, loss, pred_test_y2, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_scores = []\n",
    "pred_test_full = 0\n",
    "kf = model_selection.KFold(n_splits=5, shuffle=True, random_state=30)\n",
    "        \n",
    "for dev_index, val_index in kf.split(X, y):\n",
    "    dev_X, val_X = train_X[dev_index], train_X[val_index]\n",
    "    dev_y, val_y = train_y[dev_index], train_y[val_index]   \n",
    "         \n",
    "    pred_val, loss, pred_test,model = runLGB(dev_X, dev_y, val_X, val_y, test_X)\n",
    "    pred_test_full += pred_test\n",
    "    cv_scores.append(loss)\n",
    "    print(cv_scores)\\n\",\n",
    "    pred_test_full /= 5.\n",
    "    print(sum(cv_scores)/5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = pd.read_csv('sample_submission.csv')\n",
    "submission_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df['is_click']= pd.DataFrame(pred_test_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.to_csv('lgb_base_v3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Baseline Model - Public Leaderboard score - 0.69876663249451\n",
    "#Public Leaderboard score - 0.7296318527"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
